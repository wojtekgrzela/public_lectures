{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data analytics\n",
    "\n",
    "## Intro to statistical modelling\n",
    "\n",
    "### dr hab. inż. Jerzy Baranowski, Prof. AGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Organizational aspects\n",
    "- C3 214, office hours: Mon. 12:30-14:00\n",
    "- jb@agh.edu.pl\n",
    "- Final grade: 50% exam, 50% laboratories/project. Passing of laboratories required for attempting exam. \n",
    "- Exam in oral form (list of topics will be available)\n",
    "- Course materials, including lecture slides are available on [Github](https://github.com/KAIR-ISZ/public_lectures/tree/master/Data%20Analytics), if you see something wrong - make an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Course code\n",
    "\n",
    "### EAIiIBAiRCSS.IIi1O.34b7b98ba1017eb4b851f46d7326974f.19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Course outline\n",
    "- Introduction to Statistical Modeling\n",
    "- General concepts of Bayesian paradigm\n",
    "- Monte Carlo computation\n",
    "- Simple models and uncertanity\n",
    "- Bayesian workflow\n",
    "- Causality in models\n",
    "- Hierarchical and multilevel models\n",
    "- Model checking\n",
    "- Modeling of missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Source material - BDA 3rd edition\n",
    "Andrew Gelman et. Al\n",
    "\n",
    "<img src=\"img/bda_cover.png\" width=\"200\">\n",
    "\n",
    "- Examples in R but easily transferable.\n",
    "- Great lectures by Prof. Aki Vehtari from Alto University [link](https://aalto.cloud.panopto.eu/Panopto/Pages/Sessions/List.aspx#folderID=%22f0ec3a25-9e23-4935-873b-a9f401646812%22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Source material - Statistical Rethinking 2nd edition\n",
    "Richard McElreath\n",
    "\n",
    "<img src=\"img/statistical-rethinking.jpg\" width=\"200\">\n",
    "\n",
    "- Probably the best source for self learning of Bayesian methods\n",
    "- More code oriented, also in R, lots of additional resources, including Youtube lectures available [here](https://xcelab.net/rm/statistical-rethinking/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Source material - case studies by Michael Betancourt\n",
    "\n",
    "- Available [here](https://betanalpha.github.io/writing/)\n",
    "- More advanced, but at the same time cutting edge\n",
    "- Some content (most recent and podcasts) is available only for patrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Extra reading - Student's guide to Bayesian statistics\n",
    "\n",
    "Ben Lambert\n",
    "\n",
    "<img src=\"img/students_guide.jpg\" width=\"200\">\n",
    "\n",
    "Second \"modern\" book on Bayesian statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Extra reading - Bayesian analysis with Python\n",
    "Osvaldo Martin\n",
    "\n",
    "<img src=\"img/pmc3book.png\" width=\"200\">\n",
    "\n",
    "Actually only book based on Python, with focus on PyMC3. You need to know what you are doing. Risky choice for first contact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interesting people on Twitter\n",
    "\n",
    "- Prof Aki Vehtari [@avehtari](https://twitter.com/avehtari)\n",
    "- Prof. Andrew Gelman [@StatModeling](https://twitter.com/StatModeling) - also has an interesting blog\n",
    "- Michael Betancourt [@betanalpha](https://twitter.com/betanalpha)\n",
    "- Richard McElreath [@rlmcelreath](https://twitter.com/rlmcelreath)\n",
    "- Alex Andorra [@alex_andorra](https://twitter.com/alex_andorra) - podcast on Bayesian statisticsa\n",
    "- there will be a twitter list available on Github "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is the point?\n",
    "- We are focusing on Bayesian Data Analysis and statistical modelling\n",
    "- Models grounded in probability\n",
    "- As interpretable as possible\n",
    "- Maximally transparent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is data science?\n",
    "<img src=\"img/tierney.png\" width=\"500\">\n",
    "\n",
    "Work of data scientist intertwines both machine learning and statistical modelling and multiple other fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SM vs ML\n",
    "- Statistical modelling and machine learning are closely related fields, often hard to distinguish\n",
    "- They should not be directly compared because those comparisons are usually unfair to one or another, as they are for different problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SM\n",
    "- Incorporates probability\n",
    "- Considers data generation\n",
    "- Looks for interpretability\n",
    "- Usually regression based\n",
    "- Not limited to linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML\n",
    "- No initial structure nor traditional parameters\n",
    "- No focus on single variable\n",
    "- Does not model the process but learns from data\n",
    "- Does not rely on additivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Advantages of ML\n",
    "- ML is the best in high Signal/Noise ratios\n",
    "- Especially visual and sound recognition, language translation\n",
    "- More of a black box approach\n",
    "- Large datasets with multiple number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Advantages of SM\n",
    "- Handles small datasets better\n",
    "- Provides uncertainty estimates\n",
    "- Transparent\n",
    "- Allows investigation of influence of predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Discussion points\n",
    "- ML might need more data for the same problem as SM\n",
    "- SM needs interactions to be specified, while ML can determine them more freely\n",
    "- ML usually is a better classifier/predictor but uncertanity is not handled that well\n",
    "- ML has much more vocal advocates\n",
    "- SM requires data reduction for larger datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## When to use SM?\n",
    "- Uncertainty is important or Signal/Noise ratio is small\n",
    "- Not perfect training data\n",
    "- Isolation of particular variables effects\n",
    "- Additivity \n",
    "- Smaller samples\n",
    "- Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## When to use ML?\n",
    "- Signal/noise ratio is large and little randomness\n",
    "- Relatively unlimited training data\n",
    "- Overall prediction is important\n",
    "- Uncertanity is not\n",
    "- Expected substantial nonlinearity\n",
    "- Huge samples\n",
    "- Black box is acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Statistical Modelling\n",
    "- Three essential steps:\n",
    "- Set up full probability model\n",
    "- Condition on the observed data\n",
    "- Check and evaluate model and its posterior distribution (repeat if necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian paradigm\n",
    "- Bayesian statistics differs in two main points with frequentist statistics:\n",
    "- Data is fixed, parameters are uncertain\n",
    "- Prior knowledge is inconporated in inference\n",
    "- Everything has a probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian methods work\n",
    "Sharon Bertsch McGrayne\n",
    "\n",
    "<img src=\"img/theory.jpg\" width=\"200\">\n",
    "\n",
    "\n",
    "Available e.g. on Audible (1st month free)\n",
    "History of use of Bayesian statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Main fields of Bayesian applications\n",
    "- Social sciences\n",
    "- Medicine and biology\n",
    "- Experimental sciences\n",
    "- Diagnositics \n",
    "- Decision support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Main concepts of BDA\n",
    "- Observables and unobservables\n",
    "- Parameters $\\theta$, data $y$ and predictions $\\hat{y}$\n",
    "- Observational units and variables\n",
    "- Exchangeability\n",
    "- Explanatory variables (predictors)\n",
    "- Hierarchical modelling\n",
    "- Utility distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes’ rule derivation\n",
    "\n",
    "It all starts with joint probability\n",
    "\n",
    "$$p(\\theta,y)=p(\\theta)p(y|\\theta)$$\n",
    "\n",
    "With relatively basic transformations\n",
    "\n",
    "$$ p(\\theta|y)=\\frac{p(\\theta,y)}{p(y)}=\\frac{p(\\theta)p(y|\\theta)}{p(y)}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$p(y)=\\sum_\\theta p(\\theta)p(y|\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayes' rule\n",
    "In most applicatations we focus on the numerator\n",
    "\n",
    "$$ \\underbrace{p(\\theta|y)}_{\\mathrm{posterior}}\\propto \n",
    "\\underbrace{p(\\theta)}_{\\mathrm{prior}}\n",
    "\\underbrace{p(y|\\theta)}_{\\mathrm{likelihood}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/quote.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example – spelling correction (BDA3)\n",
    "Probability of writing ‘radom’ instead of ‘random’\n",
    "\n",
    "$$\n",
    "p(\\theta|y=\\mathrm{'radom'})\\propto p(\\theta)p(y=\\mathrm{'radom'}|\\theta)\n",
    "$$\n",
    "\n",
    "Simplifying assumptions – only 3 candidates $\\theta_1=\\mathrm{'random'}$, $\\theta_2=\\mathrm{'radon'}$ and $\\theta_3=\\mathrm{'radom'}$\n",
    "\n",
    "$$\n",
    "p(\\theta_1|y=\\mathrm{'radom'}))= \\frac{p(\\theta_1)p(y=\\mathrm{'radom'}|\\theta_1)}{\\sum_{j=1}^{3}p(\\theta_j)p(y=\\mathrm{'radom'}|\\theta_j)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example cont.\n",
    "Data comes from Google spellcheck model\n",
    "\n",
    "#### Prior distribution\n",
    "\n",
    "| $\\theta$ | $p(\\theta)$             |\n",
    "|----------|-------------------------|\n",
    "| random   | $7.60\\ \\times\\ 10^{−5}$ |\n",
    "| radon    | $6.05\\ \\times\\ 10^{−6}$ |\n",
    "| radom    | $3.12\\ \\times\\ 10^{−7}$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example cont.\n",
    "\n",
    "#### Likelyhood\n",
    "\n",
    "| $\\theta$ | $p(\\mathrm{radom}\\vert\\theta)$   |\n",
    "|----------|----------------------------------|\n",
    "| random   | 0.00193                          |\n",
    "| radon    | 0.000143000                      |\n",
    "| radom    | 0.975                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Example cont.\n",
    "Posterior distribution\n",
    "\n",
    "| $\\theta$ | $p(\\theta)p(\\mathrm{'radom'}\\vert\\theta)$ | $p(\\theta\\vert\\mathrm{'radom'})$ |\n",
    "|----------|-------------------------------------------|---------------------------------|\n",
    "| random   | $1.47\\ \\times\\ 10^{−7}$                   | $0.325000000$                           |\n",
    "| radon    | $8.65\\ \\times\\ 10^{−10}$                  | $0.002000000$                           |\n",
    "| radom    | $3.04\\ \\times\\ 10^{−7}$                   | $0.673000000$                           |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "rise": {
   "autolaunch": true,
   "backimage": "img/tlo_agh.png"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
